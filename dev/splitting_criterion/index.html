<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Splitting Criterion ¬∑ DecisionTreeAndRandomForest.jl</title><meta name="title" content="Splitting Criterion ¬∑ DecisionTreeAndRandomForest.jl"/><meta property="og:title" content="Splitting Criterion ¬∑ DecisionTreeAndRandomForest.jl"/><meta property="twitter:title" content="Splitting Criterion ¬∑ DecisionTreeAndRandomForest.jl"/><meta name="description" content="Documentation for DecisionTreeAndRandomForest.jl."/><meta property="og:description" content="Documentation for DecisionTreeAndRandomForest.jl."/><meta property="twitter:description" content="Documentation for DecisionTreeAndRandomForest.jl."/><meta property="og:url" content="https://marleenlukei.github.io/DecisionTreeAndRandomForest.jl/splitting_criterion/"/><meta property="twitter:url" content="https://marleenlukei.github.io/DecisionTreeAndRandomForest.jl/splitting_criterion/"/><link rel="canonical" href="https://marleenlukei.github.io/DecisionTreeAndRandomForest.jl/splitting_criterion/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">DecisionTreeAndRandomForest.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../getting_started/">Getting Started</a></li><li class="is-active"><a class="tocitem" href>Splitting Criterion</a><ul class="internal"><li><a class="tocitem" href="#Gini-Impurity"><span>Gini Impurity</span></a></li><li><a class="tocitem" href="#Information-Gain"><span>Information Gain</span></a></li><li><a class="tocitem" href="#Variance-Reduction"><span>Variance Reduction</span></a></li></ul></li><li><a class="tocitem" href="../dataset_examples/">Dataset Examples</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Splitting Criterion</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Splitting Criterion</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/marleenlukei/DecisionTreeAndRandomForest.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands">ÔÇõ</span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/marleenlukei/DecisionTreeAndRandomForest.jl/blob/main/docs/src/splitting_criterion.md" title="Edit source on GitHub"><span class="docs-icon fa-solid">ÔÅÑ</span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Splitting-Criterion"><a class="docs-heading-anchor" href="#Splitting-Criterion">Splitting Criterion</a><a id="Splitting-Criterion-1"></a><a class="docs-heading-anchor-permalink" href="#Splitting-Criterion" title="Permalink"></a></h1><p>This package offers multiple options of splitting criterion for evaluating the quality of a split and therefore constructing a decision tree. In the following a brief overview of the available criterion and their use cases is provided.</p><p>You can retrieve a list of the available splitting criterions with the function <code>get_split_criterions</code>, like so:</p><pre><code class="language-julia hljs">println(get_split_criterions())
println(get_split_criterions(&quot;classification&quot;))
println(get_split_criterions(&quot;regression&quot;))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(DecisionTreeAndRandomForest.split_gini, DecisionTreeAndRandomForest.split_ig, DecisionTreeAndRandomForest.split_variance)
(DecisionTreeAndRandomForest.split_gini, DecisionTreeAndRandomForest.split_ig)
(DecisionTreeAndRandomForest.split_variance,)</code></pre><h2 id="Gini-Impurity"><a class="docs-heading-anchor" href="#Gini-Impurity">Gini Impurity</a><a id="Gini-Impurity-1"></a><a class="docs-heading-anchor-permalink" href="#Gini-Impurity" title="Permalink"></a></h2><p>Gini Impurity measures the likelihood of an incorrect classification of a randomly chosen element if it is labeled according to the distribution of labels in the dataset.  Gini Impurity is primarily used in classification problems. A lower Gini impurity indicates a purer node with a higher confidence in predicting the class label. The goal is to minimize the Gini Impurity at each split, thereby creating nodes that are as pure as possible.</p><p><span>$$$Gini(S) = 1 - \sum_{i=1}^{C} (p_i)^2$$$</span></p><p>where:</p><ul><li><span>$S$</span> is the set of data points in the current node.<br/></li><li><span>$C$</span> is the number of classes.<br/></li><li><span>$p_i$</span> is the proportion of data points belonging to class <span>$i$</span> in <span>$S$</span>.<br/></li></ul><p>Steps for Calculation:</p><ol><li>Calculate Gini coefficients for each child node.</li><li>Compute the impurity for each split using a weighted Gini score.</li><li>Choose the split with the lowest Gini impurity.</li></ol><h2 id="Information-Gain"><a class="docs-heading-anchor" href="#Information-Gain">Information Gain</a><a id="Information-Gain-1"></a><a class="docs-heading-anchor-permalink" href="#Information-Gain" title="Permalink"></a></h2><p>Information Gain is calculated as the difference in entropy before and after splitting a dataset on an attribute. Entropy measures the uncertainty or impurity in the data. The goal is to reduce entropy and maximize information gain, leading to a more informative split. Information Gain is used in classification problems to choose the attribute that provides the highest information gain, resulting in the most informative split.</p><p>The information gain for a dataset ùëÜ after a split on attribute ùê¥ is given by:</p><p><span>$Gain(S, A) = Entropy(S) - \sum_{v \in \text{Values}(A)} \frac{|S_v|}{|S|} Entropy(S_v)$</span><br/></p><p>where:</p><ul><li><span>$ùê¥$</span> is a feature of the dataset.<br/></li><li><span>$v$</span> is a specific value of the feature ùê¥.<br/>  <br/></li></ul><p>Entropy is calculated as:</p><p><span>$Entropy(S) = -\sum_{i=1}^{C} p_i \log_2(p_i)$</span></p><p>where:</p><ul><li><span>$S$</span> is the set of data points in the current node.<br/></li><li><span>$C$</span> is the number of classes.<br/></li><li><span>$p_i$</span> is the proportion of data points belonging to class <span>$i$</span> in <span>$S$</span>.<br/></li></ul><p><br/>Steps for Calculation:</p><ol><li>Calculate the entropy of the original dataset ùëÜ.</li><li>For each split on attribute ùê¥ calculate the entropy of each child node <span>$ùëÜ_ùë£$</span> and calculate the weighted entropy after the split.</li><li>Compute the Information Gain by subtracting the weighted entropy from the original entropy.</li><li>Choose the split with the highest information gain.</li></ol><div class="admonition is-info"><header class="admonition-header">Info</header><div class="admonition-body"><p>While Gini Impurity and Information Gain are often used interchangeably for splitting nodes in decision trees, Gini Impurity tends to be favored when classes are balanced, while Information Gain might be preferred when dealing with imbalanced class distributions.</p></div></div><h2 id="Variance-Reduction"><a class="docs-heading-anchor" href="#Variance-Reduction">Variance Reduction</a><a id="Variance-Reduction-1"></a><a class="docs-heading-anchor-permalink" href="#Variance-Reduction" title="Permalink"></a></h2><p>Variance Reduction measures the reduction in variance of the target variable achieved by splitting a node. Higher variance reduction indicates a more informative split. Variance reduction is particularly useful for regression problems where the goal is to predict a continuous target variable.</p><p><span>$\text{VR}(S) = \sigma^2(S) - \sum_{i=1}^{n} \frac{|S_i|}{|S|} \sigma^2(S_i)$</span></p><p>where:</p><ul><li><span>$\sigma^2(S)$</span>: Variance of the parent node S.</li><li><span>$S$</span>: Set of data points in the current node.</li><li><span>$S_i$</span>: Subsets of <span>$S$</span> after the split.</li><li><span>$n$</span>: Number of subsets after the split.</li></ul><p>Steps for Calculation:</p><ol><li>Calculate the variance of the parent node <span>$S$</span>.</li><li>For each child node <span>$S_i$</span>, calculate its variance.</li><li>Compute the weighted sum of the variances of the child nodes <span>$S_i$</span>.</li><li>Subtract the weighted sum from the variance of the parent node <span>$S$</span> to get the variance reduction.</li><li>Choose the split with the highest variance reduction.</li></ol></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../getting_started/">¬´ Getting Started</a><a class="docs-footer-nextpage" href="../dataset_examples/">Dataset Examples ¬ª</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.5.0 on <span class="colophon-date" title="Saturday 13 July 2024 09:44">Saturday 13 July 2024</span>. Using Julia version 1.10.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
