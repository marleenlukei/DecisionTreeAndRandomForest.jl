<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Getting Started · DecisionTreeAndRandomForest.jl</title><meta name="title" content="Getting Started · DecisionTreeAndRandomForest.jl"/><meta property="og:title" content="Getting Started · DecisionTreeAndRandomForest.jl"/><meta property="twitter:title" content="Getting Started · DecisionTreeAndRandomForest.jl"/><meta name="description" content="Documentation for DecisionTreeAndRandomForest.jl."/><meta property="og:description" content="Documentation for DecisionTreeAndRandomForest.jl."/><meta property="twitter:description" content="Documentation for DecisionTreeAndRandomForest.jl."/><meta property="og:url" content="https://marleenlukei.github.io/DecisionTreeAndRandomForest.jl/getting_started/"/><meta property="twitter:url" content="https://marleenlukei.github.io/DecisionTreeAndRandomForest.jl/getting_started/"/><link rel="canonical" href="https://marleenlukei.github.io/DecisionTreeAndRandomForest.jl/getting_started/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">DecisionTreeAndRandomForest.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Getting Started</a><ul class="internal"><li><a class="tocitem" href="#What-is-a-Decision-Tree?"><span>What is a Decision Tree?</span></a></li><li><a class="tocitem" href="#What-is-a-Random-Forest?"><span>What is a Random Forest?</span></a></li><li><a class="tocitem" href="#Overview-of-Features"><span>Overview of Features</span></a></li><li><a class="tocitem" href="#Basic-Example-of-a-Classification-Tree"><span>Basic Example of a Classification Tree</span></a></li><li><a class="tocitem" href="#Basic-Example-of-a-Random-Forest"><span>Basic Example of a Random Forest</span></a></li><li><a class="tocitem" href="#Adding-More-Splitting-Criteria"><span>Adding More Splitting Criteria</span></a></li></ul></li><li><a class="tocitem" href="../splitting_criterion/">Splitting Criterion</a></li><li><a class="tocitem" href="../dataset_examples/">Dataset Examples</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Getting Started</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Getting Started</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/marleenlukei/DecisionTreeAndRandomForest.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/marleenlukei/DecisionTreeAndRandomForest.jl/blob/main/docs/src/getting_started.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Getting-Started-with-DecisionTreeAndRandomForest.jl"><a class="docs-heading-anchor" href="#Getting-Started-with-DecisionTreeAndRandomForest.jl">Getting Started with DecisionTreeAndRandomForest.jl</a><a id="Getting-Started-with-DecisionTreeAndRandomForest.jl-1"></a><a class="docs-heading-anchor-permalink" href="#Getting-Started-with-DecisionTreeAndRandomForest.jl" title="Permalink"></a></h1><p>This guide will introduce you to the basics of using classification trees and random forests with the <code>DecisionTreeAndRandomForest.jl</code> package.</p><h2 id="What-is-a-Decision-Tree?"><a class="docs-heading-anchor" href="#What-is-a-Decision-Tree?">What is a Decision Tree?</a><a id="What-is-a-Decision-Tree?-1"></a><a class="docs-heading-anchor-permalink" href="#What-is-a-Decision-Tree?" title="Permalink"></a></h2><p>A decision tree is a machine learning model used for both classification and regression tasks. It uses a tree-like structure where internal nodes represent features, branches represent decision rules, and each leaf node represents an outcome. Decision trees are easy to interpret and visualize, making them popular for many applications.</p><h2 id="What-is-a-Random-Forest?"><a class="docs-heading-anchor" href="#What-is-a-Random-Forest?">What is a Random Forest?</a><a id="What-is-a-Random-Forest?-1"></a><a class="docs-heading-anchor-permalink" href="#What-is-a-Random-Forest?" title="Permalink"></a></h2><p>A random forest is an ensemble learning method that constructs multiple decision trees during training and outputs the mode of the classes (classification) or mean prediction (regression) of the individual trees. This approach improves accuracy and reduces overfitting.</p><h2 id="Overview-of-Features"><a class="docs-heading-anchor" href="#Overview-of-Features">Overview of Features</a><a id="Overview-of-Features-1"></a><a class="docs-heading-anchor-permalink" href="#Overview-of-Features" title="Permalink"></a></h2><ul><li><strong>Classification Trees</strong>: Build trees for classifying data.</li><li><strong>Regression Trees</strong>: Construct trees for predicting continuous values.</li><li><strong>Random Forests</strong>: Ensemble method that combines multiple decision trees to improve accuracy and robustness.</li><li><strong>Custom Splitting Criteria</strong>: Support for various splitting criteria such as Gini Impurity, Information Gain, and Variance Reduction.</li></ul><h2 id="Basic-Example-of-a-Classification-Tree"><a class="docs-heading-anchor" href="#Basic-Example-of-a-Classification-Tree">Basic Example of a Classification Tree</a><a id="Basic-Example-of-a-Classification-Tree-1"></a><a class="docs-heading-anchor-permalink" href="#Basic-Example-of-a-Classification-Tree" title="Permalink"></a></h2><h3 id="Step-1:-Import-the-Module"><a class="docs-heading-anchor" href="#Step-1:-Import-the-Module">Step 1: Import the Module</a><a id="Step-1:-Import-the-Module-1"></a><a class="docs-heading-anchor-permalink" href="#Step-1:-Import-the-Module" title="Permalink"></a></h3><p>First, import the <code>DecisionTreeAndRandomForest</code> module:</p><pre><code class="language-julia hljs">using DecisionTreeAndRandomForest</code></pre><h3 id="Step-2:-Prepare-Training-Data"><a class="docs-heading-anchor" href="#Step-2:-Prepare-Training-Data">Step 2: Prepare Training Data</a><a id="Step-2:-Prepare-Training-Data-1"></a><a class="docs-heading-anchor-permalink" href="#Step-2:-Prepare-Training-Data" title="Permalink"></a></h3><p>Prepare some training data and their respective labels:</p><pre><code class="language-julia hljs">data = [&quot;dog&quot; 37.0; &quot;dog&quot; 38.4; &quot;dog&quot; 40.2; &quot;dog&quot; 38.9; &quot;human&quot; 36.2; &quot;human&quot; 37.4; &quot;human&quot; 38.8; &quot;human&quot; 36.2]
labels = [&quot;healthy&quot;, &quot;healthy&quot;, &quot;sick&quot;, &quot;healthy&quot;, &quot;healthy&quot;, &quot;sick&quot;, &quot;sick&quot;, &quot;healthy&quot;]</code></pre><h3 id="Step-3:-Initialize-a-Tree"><a class="docs-heading-anchor" href="#Step-3:-Initialize-a-Tree">Step 3: Initialize a Tree</a><a id="Step-3:-Initialize-a-Tree-1"></a><a class="docs-heading-anchor-permalink" href="#Step-3:-Initialize-a-Tree" title="Permalink"></a></h3><p>Initialize a classification tree:</p><pre><code class="language-julia hljs">tree = DecisionTree(split_gini)</code></pre><h3 id="Step-4:-Build-the-Tree"><a class="docs-heading-anchor" href="#Step-4:-Build-the-Tree">Step 4: Build the Tree</a><a id="Step-4:-Build-the-Tree-1"></a><a class="docs-heading-anchor-permalink" href="#Step-4:-Build-the-Tree" title="Permalink"></a></h3><p>Build the tree using the <code>fit!</code> function:</p><pre><code class="language-julia hljs">fit!(tree, data, labels)</code></pre><h3 id="Step-5:-Print-the-Tree"><a class="docs-heading-anchor" href="#Step-5:-Print-the-Tree">Step 5: Print the Tree</a><a id="Step-5:-Print-the-Tree-1"></a><a class="docs-heading-anchor-permalink" href="#Step-5:-Print-the-Tree" title="Permalink"></a></h3><p>To inspect the tree structure, simply print the tree:</p><pre><code class="language-julia hljs">print(tree)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Feature: 2, Split Value: 37.4
├── Labels: healthy (3/3)
└── Feature: 1, Split Value: dog
    ├── Labels: sick (2/2)
    └── Feature: 2, Split Value: 40.2
        ├── Labels: healthy (2/2)
        └── Labels: sick (1/1)</code></pre><h3 id="Step-6:-Classify-Test-Samples"><a class="docs-heading-anchor" href="#Step-6:-Classify-Test-Samples">Step 6: Classify Test Samples</a><a id="Step-6:-Classify-Test-Samples-1"></a><a class="docs-heading-anchor-permalink" href="#Step-6:-Classify-Test-Samples" title="Permalink"></a></h3><p>Create some test samples for classification:</p><pre><code class="language-julia hljs">test_data = [&quot;dog&quot; 38.0; &quot;human&quot; 38.0]</code></pre><p>We expect the output to be <code>healthy</code> for the first sample and <code>sick</code> for the second one.</p><h3 id="Step-7:-Predict-Labels"><a class="docs-heading-anchor" href="#Step-7:-Predict-Labels">Step 7: Predict Labels</a><a id="Step-7:-Predict-Labels-1"></a><a class="docs-heading-anchor-permalink" href="#Step-7:-Predict-Labels" title="Permalink"></a></h3><p>Retrieve the labels assigned to the test samples using the <code>predict</code> function:</p><pre><code class="language-julia hljs">prediction = predict(tree, test_data)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2-element Vector{Any}:
 &quot;healthy&quot;
 &quot;sick&quot;</code></pre><p>By following these steps, you can create and use a basic classification tree. This example illustrates how decision trees can be applied to simple datasets for classification tasks.</p><h2 id="Basic-Example-of-a-Random-Forest"><a class="docs-heading-anchor" href="#Basic-Example-of-a-Random-Forest">Basic Example of a Random Forest</a><a id="Basic-Example-of-a-Random-Forest-1"></a><a class="docs-heading-anchor-permalink" href="#Basic-Example-of-a-Random-Forest" title="Permalink"></a></h2><h3 id="Step-1:-Prepare-Training-Data"><a class="docs-heading-anchor" href="#Step-1:-Prepare-Training-Data">Step 1: Prepare Training Data</a><a id="Step-1:-Prepare-Training-Data-1"></a><a class="docs-heading-anchor-permalink" href="#Step-1:-Prepare-Training-Data" title="Permalink"></a></h3><p>Use the same training data and labels as before:</p><pre><code class="language-julia hljs">data = [&quot;dog&quot; 37.0; &quot;dog&quot; 38.4; &quot;dog&quot; 40.2; &quot;dog&quot; 38.9; &quot;human&quot; 36.2; &quot;human&quot; 37.4; &quot;human&quot; 38.8; &quot;human&quot; 36.2]
labels = [&quot;healthy&quot;, &quot;healthy&quot;, &quot;sick&quot;, &quot;healthy&quot;, &quot;healthy&quot;, &quot;sick&quot;, &quot;sick&quot;, &quot;healthy&quot;]</code></pre><h3 id="Step-2:-Initialize-a-Random-Forest"><a class="docs-heading-anchor" href="#Step-2:-Initialize-a-Random-Forest">Step 2: Initialize a Random Forest</a><a id="Step-2:-Initialize-a-Random-Forest-1"></a><a class="docs-heading-anchor-permalink" href="#Step-2:-Initialize-a-Random-Forest" title="Permalink"></a></h3><p>Initialize a random forest with the specified parameters:</p><pre><code class="language-julia hljs">forest = RandomForest(split_gini)</code></pre><h3 id="Step-3:-Build-the-Random-Forest"><a class="docs-heading-anchor" href="#Step-3:-Build-the-Random-Forest">Step 3: Build the Random Forest</a><a id="Step-3:-Build-the-Random-Forest-1"></a><a class="docs-heading-anchor-permalink" href="#Step-3:-Build-the-Random-Forest" title="Permalink"></a></h3><p>Build the random forest using the <code>fit!</code> function:</p><pre><code class="language-julia hljs">fit!(forest, data, labels)</code></pre><h3 id="Step-4:-Predict-Labels"><a class="docs-heading-anchor" href="#Step-4:-Predict-Labels">Step 4: Predict Labels</a><a id="Step-4:-Predict-Labels-1"></a><a class="docs-heading-anchor-permalink" href="#Step-4:-Predict-Labels" title="Permalink"></a></h3><p>Create some test samples for classification:</p><pre><code class="language-julia hljs">test_data = [&quot;dog&quot; 38.0; &quot;human&quot; 38.0]</code></pre><p>Retrieve the labels assigned to the test samples using the <code>predict</code> function:</p><pre><code class="language-julia hljs">forest_predictions = predict(forest, test_data)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2-element Vector{String}:
 &quot;healthy&quot;
 &quot;sick&quot;</code></pre><p>By following these steps, you can create and use a basic random forest. This example illustrates how random forests can be applied to simple datasets for classification tasks.</p><h2 id="Adding-More-Splitting-Criteria"><a class="docs-heading-anchor" href="#Adding-More-Splitting-Criteria">Adding More Splitting Criteria</a><a id="Adding-More-Splitting-Criteria-1"></a><a class="docs-heading-anchor-permalink" href="#Adding-More-Splitting-Criteria" title="Permalink"></a></h2><p>To add more splitting criteria, define a new function that computes the desired criterion. For example, to implement a Chi-Squared Split:</p><pre><code class="language-julia hljs">function chi_squared_split(data, labels, num_features)
    # Implementation of Chi-Squared split criterion
end</code></pre><p>Then use this new function when creating the tree:</p><pre><code class="language-julia hljs">tree = DecisionTree(-1, 1, -1, chi_squared_split)</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><a class="docs-footer-nextpage" href="../splitting_criterion/">Splitting Criterion »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.5.0 on <span class="colophon-date" title="Thursday 11 July 2024 15:57">Thursday 11 July 2024</span>. Using Julia version 1.10.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
